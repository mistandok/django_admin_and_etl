# Третий спринт

## Описание целей спринта 

Цель спринта - Написать ETL-процесс, который осуществляет перегонку данных из исходной базы в целевую:
1) контейнер с базой данных Postgre (исходная база, с которой забирается информация для Elasticsearch) - `database`;
2) контейнер с самим приложением Django - `service`;
3) контейнер с nginx, через который мы общаемся с приложением - `nginx`;
4) контейнер с elasticsearch (в нее загружаются данные через ETL процесс) - `elasticsearch`
5) контейнер с redis (в нем хранятся состояния, необъодимые для работы ETL-процессов) - `redis`
6) контейнер с ETL-процессом (в нем крутится скрипт, который осуществялет перегонку данных из исходной базы) - `etl`

## Запуск приложения

Для запуска приложения в локальных условиях необходимо проделать действия, описанные ниже. 
Файл настройки `docker-compose.prod.yml` располагается по пути `./docker-compose.prod.yml`.

Контейнер `service` при запуске использует ENTRYPOINT, описанный в файле `./movies_admin/start-server.sh`:
в нем ожидается подключение к PostgreSQL. После этого накатываются миграции, создается суперпользователь и приложение стартует через gunicorn.

Контейнер `etl` при запуске использует ENTRYPOINT, описанный в файле `./etl/start-etl.sh`:
в нем ожидается подключение к PostgreSQL, Redis, Elasticsearch. После этого запускается скрипт, который с заданной переодичностью осуществляет перегонку данных.

Контейнер `elasticsearch` имеет связь с внешним миром через установленные порты. Сделано для того, чтобы у вас была возможность прогнать тесты в Postman или подключиться к эластике через клиентские приложения.

1) Перейти в корневую папку папку `new_admin_panel_sprint_3`, из нее в консоли последовательно выполнить указанные команды.
2) Удаление контейнеров и томов (если уже устанавливали их ранее) - `docker-compose -f docker-compose.prod.yml down -v`
3) Запуск контейнеров с перестройкой image - `docker-compose -f docker-compose.prod.yml up -d --build` (Нужно учитывать тот факт, что Elasticsearch стартует не так быстро, как хотелось бы. Поэтому отследить состояние etl контейнера можно через его логи: `docker logs *container-id*`, как только там появятся сообщения, что все базы данных стартанули, скрипт запустит свою работу.)
4) Загрузка тестовых данных в БД (в базе появятся данные. После этого нужно немного подождать, чтобы ETL-процессы перегнали данные в Elasticsearch) - `docker-compose -f docker-compose.prod.yml exec service python manage.py loaddata dumpdata.json`

Для тестирования ETL-процессов можно пойти двумя путями:

1) Ручное тестирование: перейти по ссылке [localhost/admin](http://127.0.0.1:80/admin/), для входа в админку воспользуйтесь парой `логин/пароль: admin/admin`. Можно изменить жанры, фильмы, людей, написать запросы к Elasticsearch и посмотреть, что данные перегнались.
2) Тестирование с помощью Postman. Файл с тестами находится по пути: `./etl/postman_tests/etl_tests.json`. Их нужно импортировать в Postman и нажать на кнопку RUN.